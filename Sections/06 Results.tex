\section{Results and discussion}\label{sec:ResultsDiscussion}

\textit{Results in 2 parts.
1. part analysis
2. part future steps}


\subsection{Human factors results}
Human performance is a decisive part of remote train operation, because every control action is performed by a human operator who must interpret a video feed, react to system feedback, and compensate for delays. The results in this subsection focus on how operators respond to different levels and types of latency, and how stable versus unstable delay affects their ability to perform remote driving tasks. By comparing findings from railway, car, drone and crane studies, a sense of which latency ranges operators can adapt to, which conditions cause performance loss, and how these observations influence acceptable thresholds for remote train control. These insights form the basis for evaluating how much latency the system can tolerate before performance is affected.

In Table \ref{tab:HumanEvaluation} I have sorted some of the previously introduced papers and compared them. Method and added effect show how the research has decided to set up the tests like Sim = Simulation and IRL = In real life, while task define what the participants had to do. The results were many and varying for each research, but I have extracted a specific number the paper decided represents performance downgrade.

\import{./Tables/}{HumanFactorResults}


The columns of slight performance downgrade that was extracted for each paper are chosen from different values of evaluation. The research from Brandenburger \cite{brandenburger2023vqreactiontimertc} focus primarily on the results, measuring how fast and how accurate did the participants react to the stimulus of light signals and distance marker. Interesting founds from the report was that FPS seem to not affect the participant, at least inside the range tested, yet the bitrate was decisive for the results. Showing both higher accuracy and reaction time for higher bitrate. Another interesting result showed that the participant reacted better for the distance marker. This will be interesting forward with ERTMS as the only physical signalling the track will be markers \cite{holter2025ertmsprogramme}.
Jernberg \cite{jernberg2024} evaluate the participants by results like speed and deviation from lane, but also a self evaluation from the driver on their own performance when performing five different hazards:
\begin{itemize}
    \setlength\itemsep{0.04cm}
    \item H1/P1: Car pulling over into your lane.
    \item H2/P2: Car crossing from opposing lane threw your lane. 
    \item H3/P3: Car with "yield" does not stop in crossing.
    \item H4/P4: Child runs into traffic from behind a bus.
    \item H5/P5: Bicycle in lane that driver needs to pass in opposing lane.
\end{itemize} 
A found in Jernberg was that reaction time in H1 increased more than latency added. And with the negative results from self evaluation the paper propose that higher latency reduce awareness and put a extra mental workload on the operator. But even with this reduction, a latency of almost 300 ms did not show any more problems and the final results was that with latency tested, that only H5 at 289 ms caused performance reduction in lateral lane position.
A very similar result was confirmed by Neumeier et al. \cite{neumeier2019} where driving slalom results in participants leaving the car lane significantly more with higher latency, even with stable high latency. However as Neumeier writes "In the Parking scenario, even no differences for whatever latency could be revealed" \cite{neumeier2019}. Even Ouden et al. \cite{ouden2022}, with extremely low added latency compared to the other two car trials, did only notice a difference in the slalom driving, with then packet loss instead of latency. Ouden did not find reasonable difference between the scenarios with latency and packet loss in the straight acceleration test. 

If we compare these result to railway operation, especially train control where there are no "Cars to pull over into your lane", then are the values and results found viable? According to Jernberg \cite{jernberg2024}, when performing a study with more naturalistic driving scenarios, speed and type of task is significant for results as well as latency. A realistic driving scenario for RTO would probably not include the tests and scenarios that resulted in the performance downgrade.

The other vehicles also include interesting results form their research. Both doing a thorough test with respectively eight and six + packet loss levels of added latency. Doing so many test is thorough but needs to be done carefully and planned to avoid the participants getting eased into the added latency, unless that is the purpose. Both the crane test done by Brunnström et al. \cite{brunnström2020} and drone test by González et al. \cite{gonzález2023} contained a evaluation form called Quality of Experience (QoE) which the papers used to evaluate remote control. Here the participants rate not their own performance but how they experienced the quality of control. 
Even with the same form for evaluation, the results vary between the different vehicles. For the crane remote operation a latency of 480 ms gave a slight reduction in both QoE and effect of the work at hand, but at 880 ms it was a major decrease in effect and operability \cite{brunnström2020}. While the drone evaluation of performance found added latency of around 180 ms start causing lower performance score and QoE, and steady deterioration with more latency, and ending up with the lowest grade at around 460 ms. Yet it concludes with a E2E of 250 ms is viable for service usability, but draws the line at 300 ms. The same scores and QoE was measured to be around 0.2\% and 0.3\% packet loss.


\subsubsection{Adaptation to latency}
A topic for discussion in more of the research around remote control is the human ability to adapt to latency. Neumeier et al. \cite{neumeier2019} points this out to be one of the research questions for their paper. Even with a lot of test with different levels of mixed latency or stable and multiple runs, could they not confirm or deny any adaptation resulting in a stable latency is better than varied. The research by Jernberg et al. \cite{jernberg2024} also discuss stable latency, mentioning that the papers of Davis et al. (2010) and Gnatzig et al. (2013) found that a stable latency even as high as 500 ms \cite{jernberg2024}. A observation was that remote operators adapt to circumstances, for example driving with safety margins to reduce risks. Yet Jernberg et al. could not confirm and conclude that this was adaption to latency alone. As there was a lot of parameters tested and only up to 289 ms, the results of the test could also be credited to the differences in the individual participant, setting like rural or urban and type of hazard. 


\subsection{Measured Latency for Different Vehicles}
Different researchers have approached remote operation with their own measurement methods, system architectures and performance criteria, but the challenges of latency remain comparable. This subsection examines how latency has been measured across trains, cars, and drones, what numerical values these studies reported, and which thresholds they used to classify acceptable and unacceptable delay. By reviewing both the technical measurement approaches, such as synchronized timestamping, RTT, G2G and E2E evaluation, the results illustrate how various industries establish practical latency boundaries. This comparison provides a reference point for railway applications, showing how today's measurements are compared to thresholds and discussing how more research on a dedicated railway threshold is still needed.


Table \ref{tab:LatencyMeasured} contains the papers including own latency measurements of real test of remote control operation. Which method they use to measure, the threshold they decided to compare it to and where that threshold has its origin.

\import{./Tables/}{LatencyThresholdResults}

Latency measurements reported in the reviewed studies vary considerably, not only because different vehicles and communication technologies were tested, but also because the research community does not use a single standardised method for reporting delay. This creates challenges when comparing results across studies, as terms such as E2E, G2G, and RTT latency capture fundamentally different parts of the video transmission.

Several studies report End-to-End (E2E) latency, but the definition of E2E differs. In some cases, E2E refers to only video transmission from the sender to receiver, while other include also image capturing and image display, making it the same as G2G. While in others it also includes operator reaction time, vehicle actuation delays, or additional processing within control software. Because the boundary of the measurement is inconsistent, two studies reporting “E2E latency” may in practice have measured processes of very different scope and it is therefore important to be precise and thorough when performing and describing the results. This is seen clearly in automotive research such as Ouden \cite{ouden2022}, where E2E was separated into video latency and control latency, compared to the drone studies where E2E typically includes only camera to display time, G2G.
The G2G approach was utilized by Railway testing in D41.2 \cite{fp2r2dato2024d41_2} with synchronized devices and recorded values of 340 - 380 ms. While G2G gives a clear representation of how the video stream is experienced by a human operator, it does not indicate the contribution of individual components such as encoding, network transport, or decoding. As a result, G2G measurements are useful for assessing operational feasibility but less suitable for diagnosing technical bottlenecks.

Round-Trip Time (RTT) methods, often used in robotics and drone studies such as Kaknjo \cite{kaknjo2018videolatency} and Böhmer \cite{böhmer2020}, measure the time for a packet to travel from source to destination and back again. RTT is simple to compute but does not represent how a remote operator perceives delay. Video transmission is not normally round-trip, and RTT values can overestimate or underestimate the latency relevant for remote driving. RTT also struggles with revealing the individual components effect.

As some of the papers has specified, they have taken in use synchronized clocks. These are essential for accurate measurements as even our computers deviate by some milliseconds \cite{kozarevic2025}. Therefore more recent papers like Kozarevic \cite{kozarevic2025}, Ouden \cite{ouden2022} Jernberg \cite{jernberg2024} and more have introduced this as to not produce inaccurate results of the their setups.

Because of these methodological differences, the numerical values reported across railway, automotive, drone, and crane studies cannot be directly compared without understanding the measurement technique used. For example, a 300 ms G2G latency during tram remote control represents a complete perception delay for an operator, while a 300 ms RTT measurement in a drone test may correspond to less than half that value in actual one-way visual delay. Similarly, E2E results that include human reaction time cannot be compared to E2E results describing only transmission delay.

\subsubsection{Threshold for acceptable latency}
Across the papers about remote control there are a vast amount of results for acceptable latency. The lowest discussed as a threshold was 0 ms for drone and 500 ms for crane and car. Yet the majority ends up with a threshold around the middle of those.
After reading threw research paper on the topic of how latency threshold are set. It became apparent that very few have done enhanced research on this very topic for railway remote control. Papers such as Jürgensen \cite{jürgensen2025rcrailvehicles} and Kozarevic \cite{kozarevic2025}, who mentions the maximum latency measured before loosing performance reference sources of other vehicles and their tests of remote control. 
At the same time, Neumeier observed that some tasks, particularly predictable or hazard-free ones were not significantly affected even at higher delays. Which as discussed earlier is what tasks expected of railway. Neumeier's research directly influenced later studies as Jernberg \cite{jernberg2024} explicitly chose +100 ms and +200 ms latency increases because Neumeier had identified 300 ms as a potential upper range for manageable control. However, Jernberg also found that even smaller increases could negatively influence operator performance in complex hazard situations, indicating that thresholds are task-dependent rather than universal. Even Jürgensen \cite{jürgensen2025rcrailvehicles} decided to evaluate their results based on the results from research for remote car operation, Ouden et al. \cite{ouden2022} which also had chosen its limits from Neumeier et al. \cite{neumeier2019}. 

In the release of FP2R2DATO D5.4 in Chapter 12 \cite{fp2r2dato2023d5_4} about \textit{Degraded modes specific to remote control}, a graph about speed threshold related to video latency for RTO is proposed as you can see in Figure \ref{fig:SpeedByLatencyThreshold}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/D5_4 threshold.png}
    \caption[Threshold]{Maximum speed function of latency}
    \label{fig:SpeedByLatencyThreshold}
    \source{\cite{fp2r2dato2023d5_4}}
\end{figure}
Where as the Y-axis is not directly speed in km/h but a scaled measure of the trains max speed accredited. The figure suggest a steep reduction in speed at 150 ms, before at 400 ms that the train goes to the absolute minium speed possible \cite{fp2r2dato2023d5_4}. These numbers are not directly calculated, but rather chosen from the understanding of the author with the influence of Table \ref{fig:DistancePerTime} that show driven distance at different speeds.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/D5_4 driven distance.png}
    \caption[DistancePrTime]{Driven distance function of speed}
    \label{fig:DistancePerTime}
    \source{\cite{fp2r2dato2023d5_4}}
\end{figure}

This way to decide a threshold seem problematic. This is from Europe's Rail delivery but give no scientific grounds for the choices. Use Norway as an example where the max allowed speed for passing threw a station is 40 km/t \cite{snlrail}. Easy formula from Norwegian railway operators Bane NOR \cite{banenor}:
\[
b = \frac{v^{2}}{2r} + s
\]
given the example values of r (retardation) = 1 m/s and ignoring the s (safety). We get 61.7 m of break length. While 150 ms of latency in video control will result in 1.7 m added length which is only 2.7\% of total length. Without discussing this much further, this graph and recommendation of speed, seem very conservative, and set a maybe unrealistic and harsh threshold for railway operation.

\subsubsection{Calculation of latency}
The measurements and therefore the calculations of latency is not easily done. Since its a fluctuating measurement that varies a lot depending on the components in the system used, the way to calculate various on what the research aims to figure out.

Some studies, such as Larsen \cite{larsen2022}, estimate latency analytically by decomposing it into propagation delay, serialization delay, queueing, and processing. These models help explain why latency changes over long distances or across different network architectures, but they require detailed knowledge of the network path and still do not capture camera or display-related delays. Larsen express total communication delay as:

\[
L_{\mathrm{e2e}} = n L_{\mathrm{proc}} + (n+1)L_{\mathrm{ser}} + L_{\mathrm{prop}} + L_{Q},
\]

with processing, serialization, propagation and queueing terms depending on distance, data size, and link rate. (n = switches along the network, n+1 = number of links, LQ = queing latency)

One common approach is G2G latency, used for example in the tramway demonstrator in D41.2 \cite{fp2r2dato2024d41_2}. In that report G2G was measured by the time from light hitting the camera sensor to the moment the corresponding frame appears on the operator display. In its simplest form:

\[
L_{\mathrm{G2G}} = T_{\mathrm{display}} - T_{\mathrm{capture}}.
\]

Another widely used method is Round-Trip Time (RTT), which does not require synchronized clocks. Böhmer \cite{böhmer2020} computes RTT by sending a packet and measuring the time until the response arrives:

\[
L_{\mathrm{RTT}} = t_{r1} - t_{p1}.
\]

RTT is simple to measure but does not fully represent visual delay, since video streams are one-way.

A more detailed method of E2E is shown in Kaknjo \cite{kaknjo2018videolatency}, who measures real-time video latency by timestamping the visual events in front of the camera (\(T_1\)) and event detected on the receiving end (\(T_2\)). The start of frame processing is denoted as (\(T_3\)):

\[
L_{\mathrm{video}} =(T_2 - T_1)-(T_2 - T_3) = T_3 -T_1
\]

This isolates video-processing delay but requires accurate timestamp extraction.

All one-way methods depend on clock synchronisation; inaccurate clocks introduce measurement error. For this reason, studies such as D41.2 \cite{fp2r2dato2024d41_2} synchronised devices with atomic references, while others rely on GPS time or avoid one-way measurement entirely.

Overall, because G2G, E2E, RTT, and video-latency measurements capture different parts of the signal chain, latency values from different studies cannot be directly compared without understanding which method was used.


\subsection{Tools and protocols for remote control}
Remote operation depends not only on network performance but also on the tools and protocols used to capture, encode, transmit and display video. This subsection outlines the main technical options applied across the reviewed studies as well as encoding formats and measurement frameworks.This is done for the purpose of showing how different protocols influence latency, stability and video quality, and to compare their practical strengths and limitations for real-time control. By highlighting the variety of available tools and the results they produced in different vehicle domains, the subsection provides a foundation for identifying which approaches are most suitable for remote train operation.

\import{./Tables/}{ToolsFactorResults}

\begin{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{mejias2024}
- Evaluate latency depending on parameters / tools
Compare:
- RTSP
- WebRTC Web Real time communication
as their Real-time Transport Protocol (RTP) protocol.
- E2E
- H.264

Methodology for latency measurement.
Network Time Protocol (NTP) is necessary to synchronize sender and receiver.
Server obtains the TS1 when image is captured. Adds it to the RTP packets generated after the encoding. Player retrieves the timestamp (TS1) from the RTP packets and compares it with the current time TS2 when the image is beeing displayed. To do this, you must retrive it from the package before the decoder and comapre it with the image comming out of the decoder. 

1 Capture: the camera captures an image together with the timestamp. The timestamp is added to the metadata of the image.
2 Encoding: the image is encoded into a H.264 bit stream. The metadata is maintained unaltered along the encoding process.
3 Encapsulation: the H.264 video stream is encapsulated into RTP payload. The capture timestamp is extracted from the metadata and added to the RTP header. For this, it is required both the RTP standard header and its RFC 8286 extension.
4 Sender: RTP packets are sent on the communication channel. In the case of RTSP, the player opens a connection with the sender. For WebRTC, a negotiation between the sender and receiver is performed through the signaling server to determine the communication route.

The player receives the RTP packets through RTSP or WebRTC and calculates the latency:
1 Receiver: it receives the RTP packets through the channel established with the media server.
2 Decapsulation: the original H.264 content is extracted from the RTP payload. In addition, the timestamp contained in the RTP header is extracted and added as metadata of the H.264 content.
3 Decoding: the H.264 content is decoded to retrieve the uncompressed image. The metadata is maintained unaltered along the decoding process.
4 Displaying: the image is displayed. Moreover, the timestamp is extracted from the metadata and subtracted from the current time to obtain the End-to-End latency. This is shown to the remote driver, who will consider it during the operations.

BITRATE 
Change bitrate regarding quality of output (jitter or packet loss). Bitrate vary between 5Mbps, 3.5Mbps, 2Mbps.
A change of 2\% packet loss and 500Hz / 1000Hz jitter.

implementation.
GStreamer framework. (Open source)
Pylon source from Basler element that capture of camera images and timestamps.
H.264 NVidia en/de coder. Provided by NVIDIA graphics cards. It is the key to enable bitrate adaption.
RTP H.264 pay/depay. For packaging encoded video signal into RTP packets, and RTP includes timestamp in header.

WebRTCbin. Allows communication via WebRTC, peer2peer, must connect to signaling server responsible for negotiation.
RTSP server/client. Manage connection and send/receive data.

Camera, Media server on Jetson Xavier (Either WebRTC or RTSP), Network equipment (switch or laptop simulating a router, allowing to evaluate against bandwith degradation). Computer as player and reciver.

Results
E2E, time after capture to the time before display
S2S, time in front of camera to time displayed on player image 

Measurments for each camera and alternating available bandwidth.
When enough bandwidth results in 150 ms S2S and <75 ms E2E 
Bandwidth of <=10 results in 570 ms - 1000 ms or pixelation freezing in both S2S and E2E

RTSP
Difference in S2S and E2E is approx 70 ms - 100 ms which is image capturing and displaying.

WebRTC is faster E2E but not S2S

RTSP with rate control
Allows the bandwidth to go past 7 Mbps that was issue before, although with high latency. 
Adjust itself back up again. Also we can see a shift in latency between latency when increased bitsize of video.  

%%%%%%%%%%%%%%%
\cite{kaknjo2018videolatency}
- Evaluate latency by perfomance, (different tools) IRL, 

- G2G
- Time stamps
- H.264
- MJPEG
- RTSP (Real Time Streaming protocol)
- TCP/UDP

Found MJPEG to be 300 ms lower latency than H.264. However it found H.264 to demand less bandwitdh 50-380Kbps as it compresses more enhensive than MJPEG 4.6-5Mbps.
Found detoriation in performance in latencies above 300 ms and increase in errors during control for latencies larger than 500 ms.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Kang 2018}
\cite{kang2018}
- Evaluate latency by perfomance, (different tools) IRL, 

- 3 different resulutions (320x240, 640x480, 1280x960)
- 3 different bitrate (0.5Mbps, 1Mbps, 4Mbps)
- LTE and WiFi
- Video and camerea catching timestamps

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Larsen 2022}
\cite{larsen2022}
- Evaluation latency on perfomance, (tools) IRL

5G URLLC network
H.264

Le2e = Lprop agation + Lproc essing + Lser ialisation
Lprop = distance / v in medium
Lser = S datasize / R transmission rate

Le2e = nLproc + (n+1)Lser + Lprop + LQ 
n = switches along the network
n+1 = number of links
LQ = queing latency.

0.5 Mbps video rate in uplink and a 60 Hz update rate in downlink. Further, we assume that the higher quality video for inspection require 8 Mbps.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{böhmer2020}
- Evaluation latency on perfomance, (tools) IRL

Predictably Reliable Real-time Transport (PRRT) protocol [A. Schmidt, “Cross-layer latency-aware and -predictable data communication 2019]
The Crazyflie is controlled by Bitcraze's application layer protocol called Crazy Real-Time Protocol (CRTP)

Rasberry Pi including WiFi 2.4GHz due to Rasberry Pi constraints
timestamps by controller to drone: 
tp1 -> packet1 -> drone
tr1 <- response1 <- drone
tp2 -> packet2 -> drone
tr2 <- response2 <- drone

the Crazyradio communication path using the traditional radio link
the PRRT communication path with the Python bridge, and
the PRRT communication path with the Rust bridge.

IPT = tp2 - tp1 (Time between packets)
RTT = tr1 - tp1 (Round-trip time)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{gonzález2023}
- Evaluation tools for latency, 
- People tested

URLLC
4K quality res 1080 x 720, at 30 FPS
H.264 encoded

LTE server, LTE direct, WiFi -> avg packet delay =  500 ms, 42 ms 4 ms %Er et bilde i filutforsker hvis trengs
Can activate low latency mode. 
Connection requirments of 100 ms for video streaming, set by 3GPP TS 22.829 for unmanned aerial vehicles
Found added latency of around 180 start causing lower MOS / QoE, and steady deteriation making it 1, lowest grade at around 460 ms
concludes with a e2e of 250 ms is vaiable for service usability.

\end{comment}











\subsection{Theory v. Practical test}

Compare from the PreDraft of what expected result and hopes were, and discussing them with the information of what happend in the test and measurments.


\subsection{Future work}
- MJPEG vs H.264

- Offshore or other remote controlled vehicles that can shead light or contribute to remote control railway.

Differnt aspects of latency \textit{What is the difference}
Fixed, static v dynamic.

\begin{comment}
\subsection{Parameters for latency testing}
What parameters are we measuring. 
Latency, Jitter, Packet loss.

\subsection{Parameters for latency evaluation}
speed, distance, braking distance, reaction time, margin for error.

- Lateral Deviation
- Max Steering angle
- Out of Lane Ratio 
- Avg Speed 
- Acceleration 

\subsection{Calculations of parameters}

\end{comment}