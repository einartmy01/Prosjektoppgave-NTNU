\section{Results and discussion}\label{sec:ResultsDiscussion}

This chapter covers the result from the different research papers, and summarize some of the most relevant and important findings, as well as discuss their relevancy and application towards remote control for railway applications.

\subsection{Human factors results}
Human performance is a decisive part of remote train operation, because every control action is performed by a human operator who must interpret a video feed, react to system feedback, and compensate for delays. The results in this subsection focus on how operators respond to different levels and types of latency, and how stable versus unstable delay affects their ability to perform remote driving tasks. By comparing findings from railway, car, drone and crane studies, insight are gained into which latency ranges operators can adapt to, which conditions cause performance loss, and how these observations influence acceptable thresholds for remote train control. These insights constructs the basis for evaluating how much latency the system can tolerate before performance is affected.

In Table \ref{tab:HumanEvaluation} is some of the previously introduced papers sorted and compared. Method and added effect show how the research has decided to set up the tests, like Sim = Simulation or IRL = In real life, while task define what the participants had to do. The results were many and varying for each research, but the extracted number is a specific number the paper decides represents a performance downgrade.

\import{./Tables/}{HumanFactorResults}


The columns of slight performance downgrade that was extracted for each paper are chosen from different values of evaluation. The research from Brandenburger \cite{brandenburger2023vqreactiontimertc} focus primarily on the results, measuring how fast and how accurate did the participants react to the stimulus of light signals and distance marker. Interesting founds from the report was that FPS seem to not affect the participant, at least inside the range tested, yet the bitrate was decisive for the results. Showing both higher accuracy and reaction time for higher bitrate. Another interesting result showed that the participant reacted better for the distance marker. This will be interesting forward with ERTMS as the only physical signalling on the track will be markers \cite{holter2025ertmsprogramme}.
Jernberg \cite{jernberg2024} evaluate the participants by results like speed and deviation from lane, but also a self evaluation from the driver on their own performance when performing five different hazards:
\begin{itemize}
    \setlength\itemsep{0.04cm}
    \item H1/P1: Car pulling over into your lane.
    \item H2/P2: Car crossing from opposing lane through your lane. 
    \item H3/P3: Car with "yield" does not stop in crossing.
    \item H4/P4: Child runs into traffic from behind a bus.
    \item H5/P5: Bicycle in lane that driver needs to pass in opposing lane.
\end{itemize} 
A finding in Jernberg was that reaction time in H1 increased more than latency added. And with the negative results from self evaluation the paper propose that higher latency reduce awareness and put a extra mental workload on the operator. But even with this reduction, a latency of almost 300 ms did not show any more problems and the final results was that with all the latency tested, that only H5 at 289 ms caused performance reduction in lateral lane position.
A very similar result was confirmed by Neumeier et al. \cite{neumeier2019} where driving slalom results in participants leaving the car lane significantly more with higher latency, even with stable high latency. However as Neumeier writes "In the Parking scenario, even no differences for whatever latency could be revealed" \cite{neumeier2019}. Even Ouden et al. \cite{ouden2022}, with extremely low added latency compared to the other two car trials, did only notice a difference in the slalom driving, with then packet loss instead of latency. Ouden did not find reasonable difference between the scenarios with latency and packet loss in the straight acceleration test. 

When comparing these result to railway operation, especially train control where there are no "Cars to pull over into your lane", is the values and results found viable? According to Jernberg \cite{jernberg2024}, when performing a study with more naturalistic driving scenarios, speed and type of task is significant for results as well as latency. A realistic driving scenario for RTO would probably not include the tests and scenarios that resulted in the performance downgrade.

The other vehicles also include interesting results form their research. Both doing a thorough test with respectively eight and six levels of added latency and packet loss. Doing so many test is thorough but needs to be done carefully and planned to avoid the participants getting eased into the added latency, unless that is the purpose. Both the crane test done by Brunnström et al. \cite{brunnström2020} and drone test by González et al. \cite{gonzález2023} contained a evaluation form called Quality of Experience (QoE) which the papers used to evaluate remote control. Here the participants rate not their own performance but how they experienced the quality of control. 
Even with the same form for evaluation, the results vary between the different vehicles. For the remote crane operation a latency of 480 ms gave a slight reduction in both QoE and effect of the work at hand, but at 880 ms it was a major decrease in effect and operability \cite{brunnström2020}. While the drone evaluation of performance found added latency of around 180 ms start causing lower performance score and QoE, and steady deterioration with more latency, and ending up with the lowest grade at around 460 ms. Yet the drone test concludes with a E2E of 250 ms is viable for service usability, but draws the line at 300 ms. The same scores and QoE was measured to be around 0.2\% and 0.3\% packet loss.


\subsubsection{Adaptation to latency}
A topic for discussion in multiple of the research papers around remote control is the human ability to adapt to latency. Neumeier et al. \cite{neumeier2019} points this out to be one of the research questions for their paper. Even with a lot of test with different levels of mixed or stable latency and multiple runs, could they not confirm or deny any adaptation resulting in a stable latency being better than varied. The research by Jernberg et al. \cite{jernberg2024} also discuss stable latency, mentioning that the papers of Davis et al. (2010) and Gnatzig et al. (2013) found that a stable latency even as high as 500 ms was functional \cite{jernberg2024}. A observation was that remote operators adapt to circumstances, for example driving with safety margins to reduce risks. Yet Jernberg et al. could not confirm and conclude that this was adaption to latency alone \cite{jernberg2024}. As there was a lot of parameters tested and only up to 289 ms, the results of the test could also be credited to the differences in the individual participant, setting like rural or urban, or type of hazard. 


\subsection{Measured Latency for Different Vehicles}
Different researchers have approached remote operation with their own measurement methods, system architectures and performance criteria, but the challenges of latency remain comparable. This subsection examines how latency has been measured across trains, cars, and drones, what numerical values these studies reported, and which thresholds they used to classify acceptable and unacceptable delay. By reviewing both the technical measurement approaches, such as synchronized timestamping, RTT, G2G and E2E evaluation, the results illustrate how various industries establish practical latency boundaries. This comparison provides a reference point for railway applications, showing how today's measurements are compared to thresholds and discussing how more research on a dedicated railway threshold is still needed.


Table \ref{tab:LatencyMeasured} contains the papers including own latency measurements of real test of remote control operation. Which method they use to measure, the threshold they decided to compare it to and where that threshold has its origin.

\import{./Tables/}{LatencyThresholdResults}

Latency measurements reported in the reviewed studies vary considerably, not only because different vehicles and communication technologies were tested, but also because the research community does not use a single standardised method for reporting delay. This creates challenges when comparing results across studies, as terms such as E2E, G2G, and RTT latency capture fundamentally different parts of the video transmission.

Several studies report End-to-End (E2E) latency, but the definition of E2E differs. In some cases, E2E refers to only video transmission from the sender to receiver, while other include also image capturing and image display, making it the same as G2G. While in others it also includes operator reaction time, vehicle actuation delays, or additional processing within control software. Because the boundary of the measurement is inconsistent, two studies reporting “E2E latency” may in practice have measured processes of very different scope and it is therefore important to be precise and thorough when performing and describing the results. This is seen clearly in automotive research such as Ouden \cite{ouden2022}, where E2E was separated into video latency and control latency, compared to the drone studies where E2E typically includes only camera to display time, G2G.
The G2G approach was utilized by Railway testing in D41.2 \cite{fp2r2dato2024d41_2} with synchronized devices and recorded values of 340 - 380 ms. While G2G gives a clear representation of how the video stream is experienced by a human operator, it does not indicate the contribution of individual components such as encoding, network transport, or decoding. As a result, G2G measurements are useful for assessing operational feasibility but less suitable for diagnosing technical bottlenecks.

Round-Trip Time (RTT) methods, often used in robotics and drone studies such as Kaknjo \cite{kaknjo2018videolatency} and Böhmer \cite{böhmer2020}, measure the time for a packet to travel from source to destination and back again. RTT is simple to compute but does not represent how a remote operator perceives delay. Video transmission is not normally round-trip, and RTT values can overestimate or underestimate the latency relevant for remote driving. RTT also struggles with revealing the individual components effect.

As some of the papers has specified, they have taken in use synchronized clocks. These are essential for accurate measurements as even our computers deviate by some milliseconds \cite{kozarevic2025}. Therefore more recent papers like Kozarevic \cite{kozarevic2025}, Ouden \cite{ouden2022} Jernberg \cite{jernberg2024} and more have introduced this as to not produce inaccurate results of the their setups.

Because of these methodological differences, the numerical values reported across railway, automotive, drone, and crane studies cannot be directly compared without understanding the measurement technique used. For example, a 300 ms G2G latency during tram remote control represents a complete perception delay for an operator, while a 300 ms RTT measurement in a drone test may correspond to less than half that value in actual one-way visual delay. Similarly, E2E results that include human reaction time cannot be compared to E2E results describing only transmission delay.

\subsubsection{Threshold for acceptable latency}
Across the papers about remote control there are a vast amount of results for acceptable latency. The lowest discussed as a threshold was 0 ms for drone and 500 ms for crane and car. Yet the majority ends up with a threshold around the middle of those.
After reading through research paper on the topic of how latency threshold are set. It became apparent that very few have done enhanced research on this very topic for railway remote control. Papers such as Jürgensen \cite{jürgensen2025rcrailvehicles} and Kozarevic \cite{kozarevic2025}, who mentions the maximum latency measured before loosing performance reference sources of other vehicles and their tests of remote control. 
At the same time, Neumeier observed that some tasks, particularly predictable or hazard-free ones were not significantly affected even at higher delays. Which as discussed earlier is what tasks expected of railway. Neumeier's research directly influenced later studies as Jernberg \cite{jernberg2024} explicitly chose +100 ms and +200 ms latency increases because Neumeier had identified 300 ms as a potential upper range for manageable control. However, Jernberg also found that even smaller increases could negatively influence operator performance in complex hazard situations, indicating that thresholds are task-dependent rather than universal. Even Jürgensen \cite{jürgensen2025rcrailvehicles} decided to evaluate their results based on the results from research for remote car operation, Ouden et al. \cite{ouden2022} which also had chosen its limits from Neumeier et al. \cite{neumeier2019}. 

In the release of FP2R2DATO D5.4 in Chapter 12 \cite{fp2r2dato2023d5_4} about \textit{Degraded modes specific to remote control}, a graph about speed threshold related to video latency for RTO is proposed as you can see in Figure \ref{fig:SpeedByLatencyThreshold}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/D5_4 threshold.png}
    \caption[Threshold]{Maximum speed function of latency \cite{fp2r2dato2023d5_4}}
    \label{fig:SpeedByLatencyThreshold}
\end{figure}
Where as the Y-axis is not directly speed in km/h but a scaled measure of the trains max speed accredited. Figure \ref{fig:SpeedByLatencyThreshold} suggest a steep reduction in speed at 150 ms, before at 400 ms that the train goes to the absolute minium speed possible \cite{fp2r2dato2023d5_4}. These numbers are not directly calculated, but rather chosen from the understanding of the author with the influence of Table \ref{fig:DistancePerTime} that show driven distance at different speeds.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/D5_4 driven distance.png}
    \caption[DistancePrTime]{Driven distance function of speed \cite{fp2r2dato2023d5_4}}
    \label{fig:DistancePerTime}
\end{figure}

This way to decide a threshold seem problematic. This is from Europe's Rail delivery but give no scientific grounds for the choices. Use Norway as an example where the max allowed speed for passing through a station is 40 km/t \cite{snlrail}. Easy formula from Norwegian railway operators Bane NOR \cite{banenor}:
\[
b = \frac{v^{2}}{2r} + s
\]
given the example values of r (retardation) = 1 m/s and ignoring the s (safety). We get 61.7 m of break length. While 150 ms of latency in video control will result in 1.7 m added length which is only 2.7\% of total length. Without discussing this much further, this graph and recommendation of speed, seem very conservative, and set a maybe unrealistic and harsh threshold for railway operation.

\subsubsection{Calculation of latency}
The measurements and therefore the calculations of latency is not easily done. Since its a fluctuating measurement that varies a lot depending on the components in the system used, the way to calculate various on what the research aims to figure out.

Some studies, such as Larsen \cite{larsen2022}, estimate latency analytically by decomposing it into propagation delay, serialization delay, queueing, and processing. These models help explain why latency changes over long distances or across different network architectures, but they require detailed knowledge of the network path and still do not capture camera or display-related delays. Larsen express total communication delay as:

\[
L_{\mathrm{e2e}} = n L_{\mathrm{proc}} + (n+1)L_{\mathrm{ser}} + L_{\mathrm{prop}} + L_{Q},
\]

with processing, serialization, propagation and queueing terms depending on distance, data size, and link rate. (n = switches along the network, n+1 = number of links, LQ = queuing latency)

A more simplistic method of E2E, which can be categorized as G2G, is shown in Kaknjo \cite{kaknjo2018videolatency}, who measures real-time video latency by timestamping the visual events in front of the camera (\(T_1\)) and event detected on the receiving end (\(T_2\)). The start of frame processing is denoted as (\(T_3\)):

\[
L_{\mathrm{video}} =(T_2 - T_1)-(T_2 - T_3) = T_3 -T_1
\]

This isolates video-processing delay but requires accurate timestamp extraction.


The common approach G2G latency is used for example in the tramway demonstrator in D41.2 \cite{fp2r2dato2024d41_2}. In that report G2G was measured by the time from light hitting the camera sensor to the moment the corresponding frame appears on the operator display. In its simplest form:

\[
L_{\mathrm{G2G}} = T_{\mathrm{display}} - T_{\mathrm{capture}}.
\]

Another widely used method is Round-Trip Time (RTT), which does not require synchronized clocks. Böhmer \cite{böhmer2020} computes RTT by sending a packet and measuring the time until the response arrives:

\[
L_{\mathrm{RTT}} = t_{r1} - t_{p1}.
\]

RTT is simple to measure but does not fully represent visual delay, since video streams are one-way.


All one-way methods depend on clock synchronisation; inaccurate clocks introduce measurement error. For this reason, studies such as D41.2 \cite{fp2r2dato2024d41_2} synchronised devices with atomic references, while others rely on GPS time or avoid one-way measurement entirely.

Overall, because G2G, E2E, RTT, and video-latency measurements capture different parts of the signal chain, latency values from different studies cannot be directly compared without understanding which method was used. To complete a fully detailed study, the values of delay in transmission, capture and display should be measured. This will allow to compare to other test, but also to find bottleneck in the system.


\subsection{Tools and protocols for remote control}
Remote operation depends not only on network performance but also on the tools and protocols used to capture, encode, transmit and display video. This subsection outlines the main technical options applied across the reviewed studies as well as encoding formats and measurement frameworks.This is done for the purpose of showing how different protocols influence latency, stability and video quality, and to compare their practical strengths and limitations for real-time control. By highlighting the variety of available tools and the results they produced in different vehicle domains, the subsection provides a foundation for identifying which approaches are most suitable for RTO.

\import{./Tables/}{ToolsFactorResults}


Across the reviewed papers, remote-control video pipelines are implemented by combining a camera, an encoder, a transport protocol, and a timing or synchronization method. The choice of encoding format and protocol strongly affects latency and robustness, especially in cases where bandwidth becomes limited. A central distinction between the studies lies in whether the streaming system prioritises compression efficiency or minimal buffering. This is particularly relevant for remote train operation where predictable latency and visual clarity are required simultaneously.

One common finding is that H.264 remains the preferred codec for real-time operation due to its balance between compression efficiency and latency. This is reflected in studies on drones, cars, and trains, where H.264 is consistently used as the reference encoding configuration \cite{kaknjo2018videolatency, mejias2024, larsen2022, gonzález2023}. The codec reduces bandwidth demands under constrained network conditions and maintains an acceptable video quality at relatively low bit rates. In contrast, MJPEG prioritises immediacy by encoding each frame independently. This reduces algorithmic delay but produces significantly higher bit rates. Kaknjo found that MJPEG achieved latencies up to 300 ms lower than H.264, yet required between 4.6 and 5 Mbps compared to 50 to 380 kbps for H.264 \cite{kaknjo2018videolatency}. Although MJPEG offered the lowest encoding delay, the increased bandwidth made it more vulnerable to clogging the network. This suggest that MJPEG is beneficial only under conditions with big and stable bandwidth, which may not be the case in rural railway environments. But is something to remember if that is to change in the future.

Several studies compared transport protocols intended for real-time applications. The analysis by Mejías evaluated Real-Time Streaming Protocol (RTSP) and Web Real-Time Communication (WebRTC), both of which use the Real-time Transport Protocol (RTP) as the underlying media carrier \cite{mejias2024}. The paper introduced a detailed measurement procedure for E2E latency using Network Time Protocol (NTP) to synchronize the encoder and decoder clocks. The sender captured the timestamp at the moment of image acquisition, embedded it into RTP headers and preserved this metadata during encoding. The study showed that both protocols functioned well when bandwidth was sufficient, but once the link quality degraded their behaviour diverged. WebRTC delivered the image to the display faster but with greater visual instability, including short freezes and sections of pixelation. RTSP introduced slightly more delay, yet maintained a steadier image with fewer artefacts. 

Mejías also demonstrated that bitrate adaptation driven by Real-Time Transport Control Protocol (RTCP) feedback prevented complete video collapse during bandwidth drops and enabled gradual recovery afterwards \cite{mejias2024}. These results indicate that raw speed is less important than controlled degradation. For RTO where coverage gaps and fluctuating throughput are expected, protocols that degrade controlled and recover predictably may offer safer operational conditions than those optimised only for minimal delay.

Larsen investigated delay sources in video transmission over 5G URLLC systems and showed that most variation came from serialization and queueing in the network path rather than the application layer \cite{larsen2022}. The work also demonstrated how Time-Sensitive Networking (TSN) reduces this variation by enforcing deterministic forwarding. For RTO this could mean that predictable network level is as important as an efficient streaming tool, since unstable forwarding alone can make control unreliable even when bandwidth is sufficient.

Kang evaluated how resolution, bitrate and network choice influence practical delay under Long Term Evolution (LTE) and Wi-Fi \cite{kang2018}. Higher resolutions consistently increased delay, and LTE produced more fluctuation than Wi-Fi. González also compared LTE and Wi-Fi, more specifically LTE server routing, LTE direct mode and Wi-Fi \cite{gonzález2023}. The study found large differences between the server-routed LTE who produced delays near 500 ms, direct LTE with 10 ms, while Wi-Fi was 4 ms. For RTO this shows that routing architecture, not only protocol will have an major impact on latency.

Kozarevic and Böhmer both relied on products developed by others, but in different ways. Kozarevic used the commercial Voysys teleoperation platform to enable full-scale train tests early in the project \cite{kozarevic2025}. This allowed rapid iteration but limited insight into internal timing behaviour, which can make it difficult to identify where delay originated or adjust components for railway. Böhmer instead used the open Crazyradio ecosystem with Crazy RTP and Predictably Reliable Real-Time Transport (PRRT), gaining full visibility and the ability to tune transport behaviour \cite{böhmer2020}. For RTO, the comparison show that commercial platforms speed up deployment but reduce optimisation possibilities, while open research tools support detailed analysis but require significant redevelopment before they can meet railway safety and reliability requirements.